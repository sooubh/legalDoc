# Architecture Questions

## What are the main parts behind the scenes?

LegalEase AI is built on a modern, client-side architecture with several interconnected components working together to deliver a seamless legal document analysis experience. The system can be broadly categorized into five main architectural layers: the presentation layer, the application logic layer, the service layer, the data persistence layer, and the external API integration layer.

The presentation layer consists of React components organized into a modular component structure. The App component serves as the root orchestrator, managing application-wide state including user authentication status, current analysis results, route navigation, language preferences, and UI states such as loading indicators and modal visibility. Within this layer, the AppShell component provides the structural framework with a sidebar navigation system that allows users to move between different views: Upload, Results, Visuals, Chat, Profile, More, Lawyer Locator, Roadmap, Settings, and other auxiliary pages. The DocumentInput component handles all forms of document ingestion, whether through text pasting, PDF file uploads using drag-and-drop, or selection from pre-configured sample contracts. This component integrates with PDF.js for text extraction from PDF files and falls back to Tesseract OCR when needed for scanned documents. The AnalysisResults component renders the structured output from the AI analysis, presenting it in tabbed sections for Plain Summary, Clause Lens (with role-specific perspectives), Risk Radar, Action Points, and Legal Citations. The Visualizations component renders auto-generated Mermaid diagrams for flowcharts, timelines, and responsibility matrices. The OriginalContent component provides a sticky panel that displays the original document text or PDF viewer side-by-side with the analysis results, allowing users to reference the source material while reading the simplified explanations.

The application logic layer manages state transitions, user interactions, and business workflows. This layer is primarily implemented through React hooks and the component state management in the App component. It handles the document submission workflow where user input is collected, preferences are applied (language and simplification level), and the analysis process is initiated. The layer also manages the analysis history system, which stores both local analyses in browser localStorage and cloud-based analyses in Firestore for authenticated users. User authentication state is tracked through Firebase Auth observers, which update the application state when users log in or out. The routing system controls which view is displayed based on user navigation, with smooth transitions managed through Framer Motion animations.

The service layer contains specialized modules that handle specific functional responsibilities. The gemini.ts service is the core AI integration module, responsible for communicating with Google's Generative AI API. It implements sophisticated document chunking algorithms that split long documents into manageable segments (typically 4000 characters with 400-character overlaps) to ensure reliable processing. The chunking algorithm attempts to maintain semantic boundaries by ending chunks at paragraph breaks when possible. Each chunk is analyzed independently by the Gemini API using carefully constructed prompts that specify the exact JSON schema expected in return. The service includes robust JSON parsing with fallback mechanisms: it first attempts direct JSON parsing, then tries JSON repair using the jsonrepair library, then extracts JSON from markdown code fences, and finally extracts balanced brace-delimited JSON. The service implements intelligent merging and de-duplication logic that combines results from multiple chunks, ensuring that clauses, risks, action points, and citations are not duplicated across chunk boundaries. For clauses, it uses a composite key of title and original text to identify duplicates. For risks, it uses clause and description. For citations, it validates URLs and ensures they appear only once. If the final merged result lacks a plain summary, the service generates one by sending a separate prompt with the aggregated clauses and risks to produce a cohesive document overview.

The analysis.ts service handles persistence operations, bridging between the application state and the Firestore database. It provides functions to save analysis results to the user's history and retrieve previously saved analyses. This service integrates with Firebase authentication to associate analyses with specific users, ensuring data privacy and user-specific access. The userService.ts manages user profile data and preferences, synchronizing language settings and other user preferences between local storage and Firestore, with real-time subscription capabilities that update the UI when preferences change remotely.

The data persistence layer operates on two levels: client-side storage using browser localStorage and cloud-based storage using Firebase Firestore. The localStorage serves as a fallback and immediate storage mechanism, holding unsaved analyses, local analysis history, user language preferences, theme preferences, and other transient state. Firestore provides persistent cloud storage for authenticated users, storing complete analysis history with metadata, original document content, analysis results, visualizations, and associated metadata like timestamps and simplification levels. Firebase Authentication provides secure user authentication with email/password login and signup capabilities, managing user sessions and authentication state changes that trigger real-time updates throughout the application.

The external API integration layer connects the application to Google's Gemini API, which powers all AI-driven analysis and generation capabilities. The integration uses the Google Generative AI SDK to send requests and receive responses. The system uses the gemini-2.0-flash model for fast, cost-effective responses. The API communication is configured with specific temperature settings (0.2 for consistent outputs), maximum token limits (2048 for analysis, 512 for summaries), and enforced JSON response formats to ensure structured data returns. The system also integrates with Firebase services (Authentication, Firestore, and potentially other Firebase services) for user management and data persistence.

## How do these parts talk to each other?

The communication patterns between architectural components follow a well-defined flow that ensures data consistency, user experience continuity, and system reliability. The interaction patterns can be described through several key workflows that demonstrate how components collaborate.

When a user submits a document for analysis, the DocumentInput component triggers the handleDocumentSubmit function in the App component, passing the extracted document text (either from pasted content, PDF text extraction, or sample contract selection) along with optional metadata like PDF URLs. The App component immediately updates its state to show a loading indicator and stores the submitted content. It then calls the analyzeDocumentWithGemini function from the gemini.ts service, passing the content, selected language, and simplification level as parameters. The gemini service internally splits the content into chunks using the splitTextIntoChunks function, which attempts to create semantically meaningful segments by respecting paragraph boundaries. Each chunk is sent as a separate API request to Google's Gemini API with a carefully constructed prompt that specifies the expected JSON schema. The API responses are parsed using the safeParseJson function, which employs multiple fallback strategies to extract valid JSON even if the model includes extra text or formatting. Each parsed response is mapped to the DocumentAnalysis type structure using the mapToDocumentAnalysis function, which includes defensive validation to handle missing fields or unexpected data types. The results from all chunks are then merged using de-duplication logic that prevents repeating identical clauses, risks, actions, or citations across chunk boundaries. If no plain summary was generated from the chunks, the service makes an additional API call to generate a summary based on the merged clauses and risks. The complete DocumentAnalysis object is returned to the App component, which stores it in state and updates the route to display the Results view.

The visualization generation process occurs in parallel or immediately after the main analysis completes. The App component calls generateVisualizationsWithGemini from the gemini service, passing the original document content, language, and party labels. This service constructs a specialized prompt that requests timeline data (obligations with dates), flow diagrams (process graphs for termination, renewal, disputes), and responsibility matrices (comparing party obligations side-by-side). The response is parsed and mapped to a VisualizationBundle structure, which is stored in the App component's state and passed to the Visualizations component for rendering using Mermaid.js. The Visualizations component dynamically loads the Mermaid library and renders the diagrams as responsive SVG elements within scrollable containers to prevent overlap.

User authentication and profile synchronization work through Firebase Auth observers and Firestore subscriptions. When the App component mounts, it sets up an onAuthStateChanged observer from Firebase Auth. When a user logs in, the observer callback updates the user state in the App component. The component then calls getUserProfile to fetch the user's profile data from Firestore, which includes preferences like language settings. If the profile contains language preferences that differ from the current local state, the component synchronizes the local state and localStorage to match the cloud-stored preferences. The component also sets up a real-time subscription to the user's profile document using subscribeToUserProfile, which listens for changes to the profile in Firestore and automatically updates the UI when preferences change elsewhere (such as from another device). When a user changes their language preference in the UI, the handleLanguageChange function updates both the local state and localStorage immediately, and if the user is authenticated, it also calls updateUserPreferences to persist the change to Firestore, ensuring synchronization across devices.

Analysis history management demonstrates a hybrid storage approach with automatic fallback mechanisms. When an analysis completes, the App component creates an AnalysisHistoryItem object and immediately saves it to localStorage using the appendLocalAnalysis function, which reads the current local history, prepends the new item, limits the array to 100 items, and updates both localStorage and component state. If the user is authenticated and chooses to save the analysis to the cloud, the handleSaveAnalysis function is invoked. This function first checks if a user is authenticated, and if not, displays a login modal. For authenticated users, it calls saveAnalysisToHistory from the analysis.ts service, which creates a document in the Firestore 'analysisHistory' collection with the user ID, analysis data, original content, visualizations, metadata, and a server timestamp. The service includes comprehensive error handling with detailed logging to help diagnose issues like permission errors, authentication failures, or data format problems. If Firestore save succeeds, the returned document ID is used to update the local analysis history state. When fetching history, the getAnalysisHistoryForUser function queries Firestore for all documents matching the current user's ID, converts them to AnalysisHistoryItem objects, and returns them to the App component, which merges them with local history if needed.

State management and component communication flow through React's component props and state system. The App component maintains all application-level state and passes it down to child components as props. For example, the analysis state is passed to AnalysisResults, the visuals state to Visualizations, and the route state controls which page components render. User actions trigger callback functions passed as props: when a user clicks "Analyze Document" in DocumentInput, it calls the onSubmit prop which is bound to handleDocumentSubmit in App. When a user clicks a sidebar navigation item, it calls the onNavigate prop which updates the route state, triggering a re-render that displays the appropriate page component. The AppShell component receives callbacks for save, download, logout, language change, and navigation actions, which it triggers through its internal UI elements and passes back to the App component for state updates.

Error handling and resilience are built into the communication patterns. The gemini service includes try-catch blocks around API calls with fallback JSON parsing strategies. If a chunk fails to parse, the service logs an error but continues processing other chunks, ensuring partial results are still available. The analysis service includes error handling that gracefully degrades: if Firestore operations fail, the system continues using localStorage, and error messages are logged to help with debugging. The DocumentInput component handles PDF parsing errors by falling back to OCR, and if that fails, it displays user-friendly error messages. Throughout the system, console logging provides detailed diagnostic information during development while being mindful of not exposing sensitive data in production builds.

The real-time synchronization capabilities demonstrate how components react to external state changes. When a user profile is updated in Firestore (potentially from another device or session), the real-time subscription callback in the App component automatically receives the update and synchronizes the local state, ensuring that language preferences, theme settings, and other user preferences are immediately reflected in the UI without requiring page refreshes or manual synchronization actions.

how